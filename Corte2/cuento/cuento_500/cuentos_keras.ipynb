{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cuentos_keras",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oydIOBgm9RmI"
      },
      "source": [
        "##Importar Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReYkSKbY741X"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import sys "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucOJqKx4AQKu"
      },
      "source": [
        "###Librerias para DL (Deep Learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NksGYpA4AW-Z"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJhDR4BmAaFL",
        "outputId": "cdb218d6-d23c-4e4f-f5e0-761c48775f54"
      },
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.7.0\n",
            "Eager mode:  True\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w9JdAl7_22C"
      },
      "source": [
        "##Activando la GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuQ3uWI5_84C",
        "outputId": "c4b96c71-ac2e-48a7-d66e-aac04cd6a7ef"
      },
      "source": [
        "tf.device('/cpu:0')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f73a2ed7460>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flMQ41pRBI7c"
      },
      "source": [
        "##Descarga y preprocesado de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISKYrNE5Gp1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7931faab-0543-4b91-c963-ddeee7028ee4"
      },
      "source": [
        "fileDL= tf.keras.utils.get_file('cuentos2.txt','https://raw.githubusercontent.com/michelBolivar/Deep_learning/main/Corte2/cuento/cuentos2.txt')\n",
        "texto = open(fileDL, 'rb').read().decode(encoding='utf-8')\n",
        "texto = texto.lower()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/michelBolivar/Deep_learning/main/Corte2/cuento/cuentos2.txt\n",
            "57344/55371 [===============================] - 0s 0us/step\n",
            "65536/55371 [===================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqv3ovcOHHhD"
      },
      "source": [
        "###Entendiendo el texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OxVAGc7HLF5",
        "outputId": "41f0bf6e-4ac2-40f9-fafe-f42b5bb563f8"
      },
      "source": [
        "print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n",
        "vocab = sorted(set(texto))\n",
        "print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n",
        "print(vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el texto tiene longitud de:54195 caracteres\n",
            "el texto esta compuesto de estos :55 caracteres\n",
            "['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', '1', '2', '3', '4', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '«', '»', '¿', 'à', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '—']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMAMDZAwHZoB"
      },
      "source": [
        "###Pasar el texto a números"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWB_6ogEHevA",
        "outputId": "2ab5a2b3-7f66-4b0b-f251-7573e9c0def9"
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n",
        "idx2char = np.array(vocab)\n",
        "#pasamos todo el texto a números\n",
        "texto_como_entero= np.array([char2idx[c] for c in texto])\n",
        "print('texto: {}'.format(repr(texto[:100])))\n",
        "print('{}'.format(repr(texto_como_entero[:100])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto: 'el pantano de la luna denys barry se ha esfumado en alguna parte, en alguna región espantosa y remot'\n",
            "array([20, 27,  1, 31, 16, 29, 35, 16, 29, 30,  1, 19, 20,  1, 27, 16,  1,\n",
            "       27, 36, 29, 16,  1, 19, 20, 29, 40, 34,  1, 17, 16, 33, 33, 40,  1,\n",
            "       34, 20,  1, 23, 16,  1, 20, 34, 21, 36, 28, 16, 19, 30,  1, 20, 29,\n",
            "        1, 16, 27, 22, 36, 29, 16,  1, 31, 16, 33, 35, 20,  6,  1, 20, 29,\n",
            "        1, 16, 27, 22, 36, 29, 16,  1, 33, 20, 22, 24, 51, 29,  1, 20, 34,\n",
            "       31, 16, 29, 35, 30, 34, 16,  1, 40,  1, 33, 20, 28, 30, 35])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCqqL9DpHuJ4"
      },
      "source": [
        "###Preparar los datos para ser usados en la RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ_zcXlwHwlh",
        "outputId": "da050a42-9a9e-4d59-dbf6-02d7a85005fb"
      },
      "source": [
        "char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n",
        "#cantidad de secuencia de caracteres\n",
        "secu_length=70\n",
        "#creamos secuencias de maximo 100 caractereres\n",
        "secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n",
        "for item in secuencias.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'el pantano de la luna denys barry se ha esfumado en alguna parte, en al'\n",
            "'guna región espantosa y remota de la que nada sé. estaba con él la últi'\n",
            "'ma noche que pasó entre los hombres, y escuché sus gritos cuando el ser'\n",
            "' lo atacó; pero, ni todos los campesinos y policías del condado de meat'\n",
            "'h pudieron encontrarlo, ni a él ni a los otros, aunque los buscaron por'\n",
            "' todas partes. y ahora me estremezco cuando oigo croar a las ranas en l'\n",
            "'os pantanos o veo la luna en lugares solitarios. había intimado con den'\n",
            "'ys barry en estados unidos, donde éste se había hecho rico, y lo felici'\n",
            "'té cuando recompró el viejo castillo junto al pantano, en el somnolient'\n",
            "'o kilderry. de kilderry procedía su padre, y allí era donde quería disf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQkL9Z2hH-Jh"
      },
      "source": [
        "####Separar los datos en agrupamientos (batches)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR0Dm8vuICOZ",
        "outputId": "d7f90ae7-441a-445a-99ac-12b827623d52"
      },
      "source": [
        "#funcion para obtener el conjunto de datos de trainning\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text= chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset  = secuencias.map(split_input_target)\n",
        "\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data:  'el pantano de la luna denys barry se ha esfumado en alguna parte, en a'\n",
            "Target data:  'l pantano de la luna denys barry se ha esfumado en alguna parte, en al'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pR9wL3oIUyo",
        "outputId": "faca706a-f28a-4330-ba1b-86e8252e4f2b"
      },
      "source": [
        "#imprimimos el tensor del dataset\n",
        "print(dataset)\n",
        "#Hyper-Parametros para entrenamiento  de una rede neuronal \n",
        "#   -los datos se agrupan en batch\n",
        "BATCH_SIZE= 64 #Registro de fila\n",
        "#    -Tamaño de memoria disponible \n",
        "BUFFER_SIZE=10000\n",
        "dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print (dataset)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset shapes: ((70,), (70,)), types: (tf.int64, tf.int64)>\n",
            "<BatchDataset shapes: ((64, 70), (64, 70)), types: (tf.int64, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD5BAJ8UIgeg"
      },
      "source": [
        "##Construcción del modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAwDOQfvIirQ",
        "outputId": "14fb5d1b-74c2-4385-8a6f-f2609a6d831c"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  #creando el modelo\n",
        "  #Se utilizan tres capas \n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True,\n",
        "                         stateful=True,\n",
        "                         recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)                               \n",
        "  ])\n",
        "  return model\n",
        "vocab_size= len(vocab)\n",
        "#dimensiones de los vectores que tendrá la capa.\n",
        "embedding_dim= 256\n",
        "#cantidad de neuronas\n",
        "rnn_units=1024\n",
        "#creamos nuestra red neuronal RNN\n",
        "model=build_model(vocab_size=vocab_size,\n",
        "                  embedding_dim=embedding_dim,\n",
        "                  rnn_units=rnn_units,\n",
        "                  batch_size=BATCH_SIZE)\n",
        "#summary()para visualizar la estructura del modelo\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           14080     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 55)            56375     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,317,431\n",
            "Trainable params: 5,317,431\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-ptvydlIyKA"
      },
      "source": [
        "##Entrenando la RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vwjPgQ8I0hk"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "#En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n",
        "#con los argumentos por defecto del optimizador Adam.  \n",
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3pthC1jI-Vj"
      },
      "source": [
        "###Creando chekpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzf7x5CGJAoZ"
      },
      "source": [
        "checkpoint_dir='/content/drive/MyDrive/Deep/checkpoint'\n",
        "checkpoint_prefix= os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "902NeUnkXWQj"
      },
      "source": [
        "###Entrenando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHLv-csqXZJy",
        "outputId": "fd94af5f-4abb-48e9-8c41-4fb0d6d1508a"
      },
      "source": [
        "EPOCHS=500\n",
        "history=model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 8s 159ms/step - loss: 3.2639\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 2s 207ms/step - loss: 2.9036\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.8391\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.7039\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 2.4999\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 2.3616\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 2.2943\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 5s 485ms/step - loss: 2.2328\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 2.1864\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 2.1521\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 4s 368ms/step - loss: 2.1105\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 2.0734\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 2s 189ms/step - loss: 2.0355\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 2.0015\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.9628\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 1.9217\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 4s 408ms/step - loss: 1.8790\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 1.8309\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 2s 217ms/step - loss: 1.7822\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 1.7320\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 1.6803\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 2s 180ms/step - loss: 1.6311\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 4s 376ms/step - loss: 1.5658\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 1.5054\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 4s 376ms/step - loss: 1.4473\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 1.3791\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 1.3172\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 4s 356ms/step - loss: 1.2401\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.1650\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 5s 462ms/step - loss: 1.0907\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 1.0113\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.9375\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.8681\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 5s 497ms/step - loss: 0.8022\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 3s 304ms/step - loss: 0.7428\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.6759\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.6201\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.5771\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 4s 343ms/step - loss: 0.5340\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.4982\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 4s 368ms/step - loss: 0.4623\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.4352\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.4124\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.3952\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 3s 277ms/step - loss: 0.3783\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.3633\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 4s 417ms/step - loss: 0.3459\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.3384\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.3280\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 4s 379ms/step - loss: 0.3181\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.3063\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 4s 389ms/step - loss: 0.3043\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.2971\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.2874\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 4s 391ms/step - loss: 0.2842\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.2785\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.2710\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 3s 289ms/step - loss: 0.2691\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.2592\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 3s 297ms/step - loss: 0.2590\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.2494\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.2468\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 4s 367ms/step - loss: 0.2436\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.2413\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.2404\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 4s 328ms/step - loss: 0.2356\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.2349\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 5s 493ms/step - loss: 0.2297\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.2213\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.2197\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 4s 421ms/step - loss: 0.2176\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 0.2196\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.2149\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.2124\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.2176\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 5s 463ms/step - loss: 0.2091\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.2088\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.2076\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 4s 338ms/step - loss: 0.2082\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.2020\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1981\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 0.1969\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1959\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 5s 451ms/step - loss: 0.1939\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 0.1940\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1916\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 5s 436ms/step - loss: 0.1860\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1881\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1888\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1836\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1812\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 0.1814\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.1810\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.1796\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 5s 435ms/step - loss: 0.1779\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1783\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 5s 465ms/step - loss: 0.1784\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1734\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1755\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.1707\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.1714\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1695\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 5s 445ms/step - loss: 0.1685\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1676\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1625\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.1649\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.1638\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 4s 373ms/step - loss: 0.1641\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1648\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1595\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 5s 487ms/step - loss: 0.1627\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 2s 191ms/step - loss: 0.1597\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 6s 521ms/step - loss: 0.1572\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1586\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1575\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 4s 375ms/step - loss: 0.1564\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.1572\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 2s 187ms/step - loss: 0.1539\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1528\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.1540\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 3s 313ms/step - loss: 0.1545\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.1510\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.1487\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1503\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 4s 414ms/step - loss: 0.1511\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 2s 186ms/step - loss: 0.1470\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.1506\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1464\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.1447\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1471\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1428\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 3s 259ms/step - loss: 0.1437\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.1439\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 3s 315ms/step - loss: 0.1420\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1411\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.1403\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1414\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1386\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 0.1379\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.1377\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1354\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.1374\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1356\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1366\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 0.1372\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1356\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 5s 447ms/step - loss: 0.1348\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1330\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1336\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 0.1364\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1321\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 0.1345\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1322\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1320\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 3s 230ms/step - loss: 0.1305\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1322\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.1328\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1332\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 2s 182ms/step - loss: 0.1295\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 5s 516ms/step - loss: 0.1312\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1330\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.1302\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 3s 255ms/step - loss: 0.1281\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1262\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 3s 298ms/step - loss: 0.1304\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1301\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.1274\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 2s 217ms/step - loss: 0.1289\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1287\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 4s 389ms/step - loss: 0.1265\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1256\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1243\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 4s 351ms/step - loss: 0.1255\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1250\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1227\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.1257\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1222\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 4s 376ms/step - loss: 0.1206\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1253\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.1198\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 5s 433ms/step - loss: 0.1214\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.1231\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1223\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1230\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1182\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 4s 354ms/step - loss: 0.1216\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.1214\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1196\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1187\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1169\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 5s 492ms/step - loss: 0.1173\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.1202\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1167\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 6s 596ms/step - loss: 0.1181\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1179\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1176\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.1188\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1207\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.1170\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.1179\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 3s 277ms/step - loss: 0.1185\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1173\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1163\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 5s 489ms/step - loss: 0.1129\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.1137\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1153\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.1151\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1142\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1145\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 0.1117\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1140\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 2s 175ms/step - loss: 0.1144\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1140\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.1137\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 4s 390ms/step - loss: 0.1158\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.1150\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 4s 388ms/step - loss: 0.1126\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.1118\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.1117\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 4s 378ms/step - loss: 0.1113\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1138\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.1121\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1091\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.1124\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 4s 367ms/step - loss: 0.1092\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.1103\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1101\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 5s 507ms/step - loss: 0.1113\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1097\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 3s 229ms/step - loss: 0.1108\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1077\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1086\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 5s 434ms/step - loss: 0.1107\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1109\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1082\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 5s 475ms/step - loss: 0.1089\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.1089\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.1087\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1107\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.1097\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 5s 489ms/step - loss: 0.1064\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1061\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.1093\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1077\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1082\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.1093\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.1080\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.1070\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 4s 401ms/step - loss: 0.1091\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1083\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.1063\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1072\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1062\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 3s 283ms/step - loss: 0.1059\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1060\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1084\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 0.1037\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.1038\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 6s 541ms/step - loss: 0.1050\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.1051\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1054\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 0.1050\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1060\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 5s 482ms/step - loss: 0.1069\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 2s 192ms/step - loss: 0.1045\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1051\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 2s 194ms/step - loss: 0.1040\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1044\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1034\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 4s 396ms/step - loss: 0.1031\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1025\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 4s 417ms/step - loss: 0.1025\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1042\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1024\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 4s 335ms/step - loss: 0.1023\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1029\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1037\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 3s 292ms/step - loss: 0.1056\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1023\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.1044\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1037\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 2s 184ms/step - loss: 0.1045\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 4s 389ms/step - loss: 0.1036\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1024\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 4s 358ms/step - loss: 0.1032\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.1036\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.1037\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 5s 467ms/step - loss: 0.1025\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.1020\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1002\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1010\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.1023\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1030\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 2s 214ms/step - loss: 0.1021\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.0994\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 2s 203ms/step - loss: 0.1013\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1002\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1016\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 0.1024\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1013\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 4s 334ms/step - loss: 0.1029\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 2s 190ms/step - loss: 0.1004\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0994\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 4s 417ms/step - loss: 0.1008\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0999\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 4s 355ms/step - loss: 0.0981\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0997\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1005\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 5s 481ms/step - loss: 0.1011\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 2s 190ms/step - loss: 0.1010\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 3s 310ms/step - loss: 0.1019\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1008\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 2s 182ms/step - loss: 0.0996\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 5s 501ms/step - loss: 0.0998\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0983\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0962\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 5s 456ms/step - loss: 0.1033\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 3s 297ms/step - loss: 0.0988\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0976\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 2s 196ms/step - loss: 0.0976\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0997\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 5s 431ms/step - loss: 0.0983\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 2s 180ms/step - loss: 0.0982\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1005\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 4s 341ms/step - loss: 0.0967\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0957\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 5s 445ms/step - loss: 0.0978\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0982\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0965\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0976\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0978\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 2s 182ms/step - loss: 0.0970\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.0972\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.0974\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 3s 325ms/step - loss: 0.0985\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0984\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.1001\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 2s 205ms/step - loss: 0.0954\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0996\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 4s 406ms/step - loss: 0.0965\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0995\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0951\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 4s 414ms/step - loss: 0.0997\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0972\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 4s 370ms/step - loss: 0.0974\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0970\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0971\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.0971\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0971\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.0978\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 5s 451ms/step - loss: 0.0972\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 2s 182ms/step - loss: 0.0958\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 3s 261ms/step - loss: 0.0986\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0968\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0962\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0951\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 2s 184ms/step - loss: 0.0982\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0999\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 2s 193ms/step - loss: 0.0949\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0958\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 4s 397ms/step - loss: 0.0988\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 3s 192ms/step - loss: 0.0963\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0956\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 4s 416ms/step - loss: 0.0949\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1000\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0977\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0957\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0957\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 6s 601ms/step - loss: 0.0958\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.0959\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0969\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0954\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0930\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 3s 304ms/step - loss: 0.0960\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0962\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 4s 355ms/step - loss: 0.0960\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0951\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0963\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 6s 613ms/step - loss: 0.0938\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.0987\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 5s 472ms/step - loss: 0.0965\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.0987\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0952\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 4s 370ms/step - loss: 0.0976\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.0981\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0954\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 4s 365ms/step - loss: 0.0946\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0933\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 4s 380ms/step - loss: 0.0942\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0930\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0937\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 5s 454ms/step - loss: 0.0931\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0932\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0945\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0952\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.0952\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 6s 594ms/step - loss: 0.0944\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0966\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0937\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0955\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0935\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0918\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 3s 298ms/step - loss: 0.0948\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0928\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 4s 367ms/step - loss: 0.0935\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0940\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0935\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 5s 506ms/step - loss: 0.0925\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0927\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 0.0938\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0925\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0944\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0921\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 2s 175ms/step - loss: 0.0920\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0943\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 4s 374ms/step - loss: 0.0960\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.0943\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 4s 377ms/step - loss: 0.0958\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0942\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 2s 185ms/step - loss: 0.0951\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 5s 504ms/step - loss: 0.0938\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0949\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0917\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0909\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.0951\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 4s 373ms/step - loss: 0.0933\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 0.0943\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0933\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 5s 436ms/step - loss: 0.0921\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0932\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0924\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0931\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 2s 188ms/step - loss: 0.0954\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 4s 403ms/step - loss: 0.0926\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0931\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0915\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 4s 348ms/step - loss: 0.0947\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0909\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 4s 413ms/step - loss: 0.0956\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.0901\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0912\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 3s 298ms/step - loss: 0.0920\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0949\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0913\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 3s 310ms/step - loss: 0.0917\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0946\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 0.0909\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0938\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0904\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 0.0934\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0931\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0928\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0935\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0926\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 5s 439ms/step - loss: 0.0893\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 3s 305ms/step - loss: 0.0901\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0928\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0918\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0906\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 4s 403ms/step - loss: 0.0890\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 2s 183ms/step - loss: 0.0940\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0927\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 4s 343ms/step - loss: 0.0911\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0915\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0929\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 4s 344ms/step - loss: 0.0913\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0940\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 5s 432ms/step - loss: 0.0939\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0936\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0919\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 5s 439ms/step - loss: 0.0934\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0937\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 3s 257ms/step - loss: 0.0914\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0922\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0901\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 5s 491ms/step - loss: 0.0911\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.0910\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0904\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 4s 339ms/step - loss: 0.0938\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0910\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 4s 425ms/step - loss: 0.0894\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0878\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0877\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 4s 379ms/step - loss: 0.0896\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0885\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0899\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 3s 295ms/step - loss: 0.0907\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0897\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 5s 481ms/step - loss: 0.0895\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 2s 183ms/step - loss: 0.0905\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0882\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 4s 371ms/step - loss: 0.0896\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0913\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0912\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0913\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0935\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 6s 532ms/step - loss: 0.0915\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 2s 191ms/step - loss: 0.0899\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0892\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 3s 236ms/step - loss: 0.0917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GztYV2JPg2JT"
      },
      "source": [
        "##Generando texto nuevo usando la RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L2ufKsHg6-J"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ5SGtDhhBPM"
      },
      "source": [
        "#funcion para generar texto\n",
        "def generate_text(model, start_string):\n",
        "  #definimos cuantos tensores\n",
        "  num_generate=500\n",
        "  #convertimos el texto en números\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval= tf.expand_dims (input_eval,0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 0.5  \n",
        "  #entre más alta la temperatura más creatividad al modelo, pero tambien\n",
        "  #más errores ortograficos.\n",
        "  model.reset_states()\n",
        "  #bucle para generar caracteres, mediante predicciones\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval= tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append (idx2char[predicted_id])\n",
        "  \n",
        "  return (start_string+ ''.join(text_generated))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFqCKBhphGqz"
      },
      "source": [
        "###Generando texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_Kqwrk3hK6d",
        "outputId": "db8cda23-4739-414a-a4a3-609e39cd04a5"
      },
      "source": [
        "print(generate_text(model, start_string=u\"merodeando sobre las aguas\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merodeando sobre las aguas que no la fameniza de tras estansinados y los primeros de los primeros pero tudo perseguido espantosa y cuando los alegres como no había dermido y invación con falaba teciliero que de no pen alguna tande una maldición que, en adelante, afligiría a la casa de c. «nunca sea que un noble de tumento a los condes de fiente en el brejo de la colina se encontró sumido en la base de tambría y el elixir de la eterna juventud, y tenía fama de ducho con el castillo de la noche. el conde murió sin decir pa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfgT6exUhkfj"
      },
      "source": [
        "##Exportando modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK4OQlAOhoq_",
        "outputId": "2ea05ccc-0160-4122-be92-9392ae3e42e1"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "import os\n",
        "# Serializamos el modelo en forma JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"modelRNN_cuentos2.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/MyDrive/Deep/Modelo/modelRNN_cuentos2_pesos.hdf5\")\n",
        "model.save('modelRNN_cuentos2.h5')\n",
        "print(\"modelo salvado en disco\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "modelo salvado en disco\n"
          ]
        }
      ]
    }
  ]
}